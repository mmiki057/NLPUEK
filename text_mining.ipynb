{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e40a35",
   "metadata": {},
   "source": [
    "### Import packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "584a9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc95a905",
   "metadata": {},
   "source": [
    "### Create documents corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c152165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "/var/folders/mq/2wx6tt_54gscrk4qmy80b1vc0000gn/T/ipykernel_99782/3955440263.py:2: SyntaxWarning: invalid escape sequence '\\.'\n",
      "  corpus = PlaintextCorpusReader(corpus_dir, '.*\\.txt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Chronicles of Narnia. Prince Caspian.txt',\n",
       " 'Chronicles of Narnia. The Horse and His Boy.txt',\n",
       " 'Chronicles of Narnia. The Last Battle.txt',\n",
       " 'Chronicles of Narnia. The Lion, the Witch and the Wardrobe.txt',\n",
       " 'Chronicles of Narnia. The Magicians Nephew.txt',\n",
       " 'Chronicles of Narnia. The Silver Chair.txt',\n",
       " 'Chronicles of Narnia. The Voyage of the Dawn Treader.txt',\n",
       " 'Fantastic Beasts and Where to Find Them.txt',\n",
       " 'Fantastic Beasts. The Crimes of Grindelwald.txt',\n",
       " 'Fantastic Beasts. The Secrets of Dumbledore.txt',\n",
       " 'Harry Potter and the Chamber of Secrets.txt',\n",
       " 'Harry Potter and the Deathly Hallows Part 1.txt',\n",
       " 'Harry Potter and the Deathly Hallows Part 2.txt',\n",
       " 'Harry Potter and the Goblet of Fire.txt',\n",
       " 'Harry Potter and the Half-Blood Prince.txt',\n",
       " 'Harry Potter and the Order of the Phoenix.txt',\n",
       " 'Harry Potter and the Philosophers Stone.txt',\n",
       " 'Harry Potter and the Prisoner of Azkaban.txt',\n",
       " 'Twilight Saga. Breaking Dawn Part 1.txt',\n",
       " 'Twilight Saga. Breaking Dawn Part 2.txt',\n",
       " 'Twilight Saga. Eclipse.txt',\n",
       " 'Twilight Saga. New Moon.txt',\n",
       " 'Twilight Saga. Twilight.txt']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dir = \"./Literature-original\"\n",
    "corpus = PlaintextCorpusReader(corpus_dir, '.*\\.txt')\n",
    "files_names = corpus.fileids()\n",
    "files_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fda77",
   "metadata": {},
   "source": [
    "### Corpus documents preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ddfaedb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = {}\n",
    "for file_name in files_names:\n",
    "    documents[file_name] = corpus.raw(file_name)\n",
    "#print(json.dumps(documents, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f6aa518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = {}\n",
    "for file_name in documents:\n",
    "    length[file_name] = {\n",
    "        \"pre\": len(word_tokenize(documents[file_name])),\n",
    "    }\n",
    "#print(json.dumps(length, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3a36133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e31656f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_post = {}\n",
    "for file_name in documents:\n",
    "    documents[file_name] = documents[file_name].lower()\n",
    "    documents[file_name] = \"\".join([char for char in documents[file_name] if char not in string.punctuation])\n",
    "    documents[file_name] = \"\".join([char for char in documents[file_name] if char not in string.digits])\n",
    "    documents[file_name] = \" \".join([ps.stem(word) for word in word_tokenize(documents[file_name])])\n",
    "    documents[file_name] = \" \".join(word for word in word_tokenize(documents[file_name]) if word not in stopwords.words('english'))\n",
    "#print(json.dumps(documents, indent=4, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "40803f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in documents:\n",
    "    length[file_name][\"post\"] = len(word_tokenize(documents[file_name]))\n",
    "#print(json.dumps(length, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "45f29323",
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = pd.DataFrame.from_dict(length, orient='index')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "250c2a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre</th>\n",
       "      <th>post</th>\n",
       "      <th>diff</th>\n",
       "      <th>pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. Prince Caspian.txt</th>\n",
       "      <td>657</td>\n",
       "      <td>339</td>\n",
       "      <td>318</td>\n",
       "      <td>0.484018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Horse and His Boy.txt</th>\n",
       "      <td>850</td>\n",
       "      <td>448</td>\n",
       "      <td>402</td>\n",
       "      <td>0.472941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Last Battle.txt</th>\n",
       "      <td>1101</td>\n",
       "      <td>562</td>\n",
       "      <td>539</td>\n",
       "      <td>0.489555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Lion, the Witch and the Wardrobe.txt</th>\n",
       "      <td>793</td>\n",
       "      <td>389</td>\n",
       "      <td>404</td>\n",
       "      <td>0.509458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Magicians Nephew.txt</th>\n",
       "      <td>1250</td>\n",
       "      <td>622</td>\n",
       "      <td>628</td>\n",
       "      <td>0.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Silver Chair.txt</th>\n",
       "      <td>1275</td>\n",
       "      <td>620</td>\n",
       "      <td>655</td>\n",
       "      <td>0.513725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Voyage of the Dawn Treader.txt</th>\n",
       "      <td>1203</td>\n",
       "      <td>595</td>\n",
       "      <td>608</td>\n",
       "      <td>0.505403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts and Where to Find Them.txt</th>\n",
       "      <td>765</td>\n",
       "      <td>416</td>\n",
       "      <td>349</td>\n",
       "      <td>0.456209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts. The Crimes of Grindelwald.txt</th>\n",
       "      <td>761</td>\n",
       "      <td>440</td>\n",
       "      <td>321</td>\n",
       "      <td>0.421813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts. The Secrets of Dumbledore.txt</th>\n",
       "      <td>635</td>\n",
       "      <td>360</td>\n",
       "      <td>275</td>\n",
       "      <td>0.433071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Chamber of Secrets.txt</th>\n",
       "      <td>844</td>\n",
       "      <td>451</td>\n",
       "      <td>393</td>\n",
       "      <td>0.465640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Deathly Hallows Part 1.txt</th>\n",
       "      <td>796</td>\n",
       "      <td>433</td>\n",
       "      <td>363</td>\n",
       "      <td>0.456030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Deathly Hallows Part 2.txt</th>\n",
       "      <td>799</td>\n",
       "      <td>442</td>\n",
       "      <td>357</td>\n",
       "      <td>0.446809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Goblet of Fire.txt</th>\n",
       "      <td>784</td>\n",
       "      <td>433</td>\n",
       "      <td>351</td>\n",
       "      <td>0.447704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Half-Blood Prince.txt</th>\n",
       "      <td>782</td>\n",
       "      <td>442</td>\n",
       "      <td>340</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Order of the Phoenix.txt</th>\n",
       "      <td>785</td>\n",
       "      <td>434</td>\n",
       "      <td>351</td>\n",
       "      <td>0.447134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Philosophers Stone.txt</th>\n",
       "      <td>781</td>\n",
       "      <td>436</td>\n",
       "      <td>345</td>\n",
       "      <td>0.441741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Prisoner of Azkaban.txt</th>\n",
       "      <td>719</td>\n",
       "      <td>404</td>\n",
       "      <td>315</td>\n",
       "      <td>0.438108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Breaking Dawn Part 1.txt</th>\n",
       "      <td>821</td>\n",
       "      <td>400</td>\n",
       "      <td>421</td>\n",
       "      <td>0.512789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Breaking Dawn Part 2.txt</th>\n",
       "      <td>860</td>\n",
       "      <td>425</td>\n",
       "      <td>435</td>\n",
       "      <td>0.505814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Eclipse.txt</th>\n",
       "      <td>785</td>\n",
       "      <td>385</td>\n",
       "      <td>400</td>\n",
       "      <td>0.509554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. New Moon.txt</th>\n",
       "      <td>763</td>\n",
       "      <td>393</td>\n",
       "      <td>370</td>\n",
       "      <td>0.484928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Twilight.txt</th>\n",
       "      <td>566</td>\n",
       "      <td>286</td>\n",
       "      <td>280</td>\n",
       "      <td>0.494700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pre  post  diff       pct\n",
       "Chronicles of Narnia. Prince Caspian.txt             657   339   318  0.484018\n",
       "Chronicles of Narnia. The Horse and His Boy.txt      850   448   402  0.472941\n",
       "Chronicles of Narnia. The Last Battle.txt           1101   562   539  0.489555\n",
       "Chronicles of Narnia. The Lion, the Witch and t...   793   389   404  0.509458\n",
       "Chronicles of Narnia. The Magicians Nephew.txt      1250   622   628  0.502400\n",
       "Chronicles of Narnia. The Silver Chair.txt          1275   620   655  0.513725\n",
       "Chronicles of Narnia. The Voyage of the Dawn Tr...  1203   595   608  0.505403\n",
       "Fantastic Beasts and Where to Find Them.txt          765   416   349  0.456209\n",
       "Fantastic Beasts. The Crimes of Grindelwald.txt      761   440   321  0.421813\n",
       "Fantastic Beasts. The Secrets of Dumbledore.txt      635   360   275  0.433071\n",
       "Harry Potter and the Chamber of Secrets.txt          844   451   393  0.465640\n",
       "Harry Potter and the Deathly Hallows Part 1.txt      796   433   363  0.456030\n",
       "Harry Potter and the Deathly Hallows Part 2.txt      799   442   357  0.446809\n",
       "Harry Potter and the Goblet of Fire.txt              784   433   351  0.447704\n",
       "Harry Potter and the Half-Blood Prince.txt           782   442   340  0.434783\n",
       "Harry Potter and the Order of the Phoenix.txt        785   434   351  0.447134\n",
       "Harry Potter and the Philosophers Stone.txt          781   436   345  0.441741\n",
       "Harry Potter and the Prisoner of Azkaban.txt         719   404   315  0.438108\n",
       "Twilight Saga. Breaking Dawn Part 1.txt              821   400   421  0.512789\n",
       "Twilight Saga. Breaking Dawn Part 2.txt              860   425   435  0.505814\n",
       "Twilight Saga. Eclipse.txt                           785   385   400  0.509554\n",
       "Twilight Saga. New Moon.txt                          763   393   370  0.484928\n",
       "Twilight Saga. Twilight.txt                          566   286   280  0.494700"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths['diff'] = lengths['pre'] - lengths['post']\n",
    "lengths['pct'] = lengths['diff'] / lengths['pre']\n",
    "lengths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d887b",
   "metadata": {},
   "source": [
    "### Create frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d75dfc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. Prince Caspian.txt</th>\n",
       "      <td>peter susan edmund luci pevensi magic whisk aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Horse and His Boy.txt</th>\n",
       "      <td>boy name shasta ha live life rememb southern p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Last Battle.txt</th>\n",
       "      <td>western region narnia clever greedi ape shift ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Lion, the Witch and the Wardrobe.txt</th>\n",
       "      <td>peter susan edmund luci pevensi evacu london e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Magicians Nephew.txt</th>\n",
       "      <td>stori begin london dure summer two children di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Silver Chair.txt</th>\n",
       "      <td>eustac scrubb reform charact follow event voya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chronicles of Narnia. The Voyage of the Dawn Treader.txt</th>\n",
       "      <td>two youngest pevensi children luci edmund stay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts and Where to Find Them.txt</th>\n",
       "      <td>british wizard magizoologist newton newt scama...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts. The Crimes of Grindelwald.txt</th>\n",
       "      <td>magic congress unit state america macusa trans...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fantastic Beasts. The Secrets of Dumbledore.txt</th>\n",
       "      <td>albu dumbledor gellert grindelwald briefli mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Chamber of Secrets.txt</th>\n",
       "      <td>spend summer dursley harri potter meet dobbi h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Deathly Hallows Part 1.txt</th>\n",
       "      <td>malfoy manor severu snape meet lord voldemort ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Deathly Hallows Part 2.txt</th>\n",
       "      <td>buri dobbi harri potter ask goblin griphook he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Goblet of Fire.txt</th>\n",
       "      <td>harri potter ha nightmar muggl caretak murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Half-Blood Prince.txt</th>\n",
       "      <td>lord voldemort tighten hi grip wizard muggl wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Order of the Phoenix.txt</th>\n",
       "      <td>stay dursley harri potter dudley attack dement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Philosophers Stone.txt</th>\n",
       "      <td>late one night albu dumbledor minerva mcgonaga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Harry Potter and the Prisoner of Azkaban.txt</th>\n",
       "      <td>hi second year hogwart harri potter spend anot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Breaking Dawn Part 1.txt</th>\n",
       "      <td>month event previou film day bella swan edward...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Breaking Dawn Part 2.txt</th>\n",
       "      <td>bella ha given birth awaken humantovampir tran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Eclipse.txt</th>\n",
       "      <td>seattl far fork victoria attack riley bier beg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. New Moon.txt</th>\n",
       "      <td>eighteenth birthday bella swan awaken dream ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Twilight Saga. Twilight.txt</th>\n",
       "      <td>seventeenyearold bella swan leav phoenix arizo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              content\n",
       "Chronicles of Narnia. Prince Caspian.txt            peter susan edmund luci pevensi magic whisk aw...\n",
       "Chronicles of Narnia. The Horse and His Boy.txt     boy name shasta ha live life rememb southern p...\n",
       "Chronicles of Narnia. The Last Battle.txt           western region narnia clever greedi ape shift ...\n",
       "Chronicles of Narnia. The Lion, the Witch and t...  peter susan edmund luci pevensi evacu london e...\n",
       "Chronicles of Narnia. The Magicians Nephew.txt      stori begin london dure summer two children di...\n",
       "Chronicles of Narnia. The Silver Chair.txt          eustac scrubb reform charact follow event voya...\n",
       "Chronicles of Narnia. The Voyage of the Dawn Tr...  two youngest pevensi children luci edmund stay...\n",
       "Fantastic Beasts and Where to Find Them.txt         british wizard magizoologist newton newt scama...\n",
       "Fantastic Beasts. The Crimes of Grindelwald.txt     magic congress unit state america macusa trans...\n",
       "Fantastic Beasts. The Secrets of Dumbledore.txt     albu dumbledor gellert grindelwald briefli mee...\n",
       "Harry Potter and the Chamber of Secrets.txt         spend summer dursley harri potter meet dobbi h...\n",
       "Harry Potter and the Deathly Hallows Part 1.txt     malfoy manor severu snape meet lord voldemort ...\n",
       "Harry Potter and the Deathly Hallows Part 2.txt     buri dobbi harri potter ask goblin griphook he...\n",
       "Harry Potter and the Goblet of Fire.txt             harri potter ha nightmar muggl caretak murder ...\n",
       "Harry Potter and the Half-Blood Prince.txt          lord voldemort tighten hi grip wizard muggl wo...\n",
       "Harry Potter and the Order of the Phoenix.txt       stay dursley harri potter dudley attack dement...\n",
       "Harry Potter and the Philosophers Stone.txt         late one night albu dumbledor minerva mcgonaga...\n",
       "Harry Potter and the Prisoner of Azkaban.txt        hi second year hogwart harri potter spend anot...\n",
       "Twilight Saga. Breaking Dawn Part 1.txt             month event previou film day bella swan edward...\n",
       "Twilight Saga. Breaking Dawn Part 2.txt             bella ha given birth awaken humantovampir tran...\n",
       "Twilight Saga. Eclipse.txt                          seattl far fork victoria attack riley bier beg...\n",
       "Twilight Saga. New Moon.txt                         eighteenth birthday bella swan awaken dream ol...\n",
       "Twilight Saga. Twilight.txt                         seventeenyearold bella swan leav phoenix arizo..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = pd.DataFrame.from_dict(documents, orient='index')\n",
    "docs.columns = ['content']\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4aaeeaeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 6019 stored elements and shape (23, 2503)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = TfidfVectorizer()\n",
    "cv = CountVectorizer()\n",
    "matrix_tfidf = tv.fit_transform(docs['content'])\n",
    "matrix_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5eec9325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8954472024874498"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparcity_tfidf = 1-(matrix_tfidf.getnnz()/(matrix_tfidf.shape[0]*matrix_tfidf.shape[1]))\n",
    "sparcity_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8c4992",
   "metadata": {},
   "source": [
    "### Directories for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ef6819c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./worldclouds'):\n",
    "    os.mkdir('./wordclouds')\n",
    "if not os.path.exists('./topic_modeling'):\n",
    "    os.mkdir('./topic_modeling')\n",
    "if not os.path.exists('./topic_modeling/topics'):\n",
    "    os.mkdir('./topic_modeling/topics')\n",
    "if not os.path.exists('./topic_modeling/documents'):\n",
    "    os.mkdir('./topic_modeling/documents')\n",
    "if not os.path.exists('./clustering'):\n",
    "    os.mkdir('./clustering')\n",
    "if not os.path.exists('./ngrams'):\n",
    "    os.mkdir('./ngrams')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08664456",
   "metadata": {},
   "source": [
    "### Worldclouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3863f156",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    background_color ='white',\n",
    "    max_words = 5000,\n",
    "    contour_width =3,\n",
    "    contour_color ='steelblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a04f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in docs.iterrows():\n",
    "    wordcloud.generate(row['content'])\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(index.replace(\".txt\",\"\"))\n",
    "    plt.savefig('./wordclouds/{}'.format(index.replace(\"txt\",\"png\")))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc6220",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d95db590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, title, size):\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"]\n",
    "    fig, axes = plt.subplots(*size, figsize=(30, 15), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[-n_top_words:]\n",
    "        top_features = feature_names[top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7, color=colors[topic_idx])\n",
    "        ax.set_title(f\"Topic {topic_idx + 1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.savefig(f'./topic_modeling/topics/{title}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "45e1941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_documents(model, matrix, n_topics, title):\n",
    "    colors = [\"red\", \"blue\", \"green\", \"orange\", \"purple\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"]\n",
    "    docs_topics = pd.DataFrame(model.transform(matrix), columns=[f'Topic {x}' for x in range(n_topics)])\n",
    "    docs_topics.index = [file_name.replace(\".txt\",\"\") for file_name in files_names]\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    left = [0] * len(docs_topics)\n",
    "    for i, col in enumerate(docs_topics.columns):\n",
    "        plt.barh(docs_topics.index, docs_topics[col], left=left, label=col, color=colors[i])\n",
    "        left = [left[j] + docs_topics[col].iloc[j] for j in range(len(docs_topics))]\n",
    "    plt.savefig(f'./topic_modeling/documents/{title}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f7d62d34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[76]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m n_topics = \u001b[32m10\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m features_names = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m n_top_words = \u001b[32m20\u001b[39m\n\u001b[32m      4\u001b[39m size = (\u001b[32m2\u001b[39m, \u001b[32m5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UEK/Natural Language Processing/venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:1473\u001b[39m, in \u001b[36mCountVectorizer.get_feature_names_out\u001b[39m\u001b[34m(self, input_features)\u001b[39m\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_feature_names_out\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_features=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1461\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get output feature names for transformation.\u001b[39;00m\n\u001b[32m   1462\u001b[39m \n\u001b[32m   1463\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1471\u001b[39m \u001b[33;03m        Transformed feature names.\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.asarray(\n\u001b[32m   1475\u001b[39m         [t \u001b[38;5;28;01mfor\u001b[39;00m t, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocabulary_.items(), key=itemgetter(\u001b[32m1\u001b[39m))],\n\u001b[32m   1476\u001b[39m         dtype=\u001b[38;5;28mobject\u001b[39m,\n\u001b[32m   1477\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/UEK/Natural Language Processing/venv/lib/python3.13/site-packages/sklearn/feature_extraction/text.py:501\u001b[39m, in \u001b[36m_VectorizerMixin._check_vocabulary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_vocabulary()\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_vocabulary_:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mVocabulary not fitted or provided\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocabulary_) == \u001b[32m0\u001b[39m:\n\u001b[32m    504\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mVocabulary is empty\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNotFittedError\u001b[39m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "n_topics = 10\n",
    "features_names = cv.get_feature_names_out()\n",
    "n_top_words = 20\n",
    "size = (2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb1cb",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4def9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1202a7d5",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e08c798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
